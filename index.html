<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="NTIRE 2025 | The First Challenge on Day and Night Raindrop Removal for Dual-Focused Images">
  <meta name="keywords" content="UCIP">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>NTIRE 2025 | The First Challenge on Day and Night Raindrop Removal for Dual-Focused Images</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script type="text/javascript" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

<!--       <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://renyulin-f.github.io/MoE-DiffIR.github.io/">
            MoE-DiffIR
          </a>
          <a class="navbar-item" href="https://lixinustc.github.io/projects/KVQ/">
            KVQ
          </a>
           <a class="navbar-item" href="https://wxrui182.github.io/CoNo.github.io/">
            CoNo
          </a>
        </div>
      </div> -->
    </div>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">NTIRE 2025 | The First Challenge on Day and Night Raindrop Removal for Dual-Focused Images</h1>
<!--           <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=sbiY97gAAAAJ&hl=en">Xin Li</a><sup>*1</sup>,</span>
             <span class="author-block">
              <a href="https://scholar.google.com/citations?user=Z8PYhA4AAAAJ&hl=en">Yeying Jin</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=qHeWjNwAAAAJ&hl=en&authuser=1">Zongwei Wu</a><sup>*1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=XZugqiwAAAAJ&hl=en">Bingchen Li</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=MbVZAGQAAAAJ&hl=en">Wenhan Yang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=en&user=234Nza8AAAAJ">Yu Li</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=1ayDJfsAAAAJ&hl=zh-CN">Zhibo Chen</a><sup>1</sup>
            </span>
             <span class="author-block">
              <a href="https://scholar.google.com/citations?user=1ayDJfsAAAAJ&hl=zh-CN">Bihan Wen</a><sup>1</sup>
            </span>
             <span class="author-block">
              <a href="https://scholar.google.com/citations?user=1ayDJfsAAAAJ&hl=zh-CN">Robby T. Tan</a><sup>1</sup>
            </span>
             <span class="author-block">
              <a href="https://scholar.google.com/citations?user=1ayDJfsAAAAJ&hl=zh-CN">Radu.Timofte</a><sup>1</sup>
            </span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">(* Equal Contributions, ECCV 2024) </span>
        </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Science and Technology of China,</span>
            <span class="author-block"><sup>2</sup>National University of Singapore,</span>
            <span class="author-block"><sup>3</sup>Microsoft Research Asia</span>
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
               <span class="link-block">
                <a href="https://codalab.lisn.upsaclay.fr/competitions/21345"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-trophy"></i>
                  </span>
                  <span>Competitions</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2504.12711"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
<!--               <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a> -->
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/YaPL0dI5l0U?si=Jqd37V2I7mgQpn-2"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>    
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/jinyeying/RaindropClarity"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/jinyeying/RaindropClarity"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h1 class="title is-3">Organizers</h2>
        <div class="content has-text-justified">
          <p>
  <style>
    /* 外层容器，使用 Flex 布局，并自动换行 */
    .container {
      display: flex;
      flex-wrap: wrap;
      justify-content: center; /* 居中对齐 */
      gap: 10px;  /* 每个项目之间的间距 */
      max-width: 1000px; /* 根据需要调整总宽度 */
      margin: 0 auto;
    }
    /* 每个人的外层容器 */
    .person {
      /* 保证每行6个 */
      flex: 0 0 calc(100% / 6 - 20px);
      display: flex;
      justify-content: center;
    }
    /* 圆形背景容器 */
    .circle {
      width: 100px;       /* 可调整圆形直径 */
      height: 100px;
      background-color: #add8e6; /* 圆形背景色 */
      border-radius: 50%; /* 使容器变成圆形 */
      display: flex;
      align-items: center;
      justify-content: center;
    }
    /* 图片样式 */
    .circle img {
      width: 95%;       /* 图片宽度占圆形的 90% */
      height: 95%;      /* 图片高度占圆形的 90% */
      object-fit: cover; /* 保持图片比例，超出部分自动裁剪 */
      border-radius: 50%; /* 使图片也呈现圆形 */
    }
    /* 响应式调整（例如屏幕较窄时每行显示3个） */
    @media (max-width: 768px) {
      .person {
        flex: 0 0 calc(100% / 3 - 20px);
      }
    }
  </style>
</head>
<body>
  <div class="container">
    <!-- 下面示例了12个照片，你需要将 src 替换为实际图片路径 -->
    <div class="person">
      <figure>
      <div class="circle">
        <img src="./imgs/xin_li.jpg" alt="Xin Li">
      </div>
        <figcaption style="font-size: 8px;">Xin Li<br>USTC</figcaption>
      </figure>
    </div>
    <div class="person">
       <figure>
      <div class="circle">
        <img src="./imgs/YeyingJin.png" alt="Yeying Jin">
      </div>
        <figcaption style="font-size: 8px;">Yeying Jin<br>NUS | Tencent</figcaption>
      </figure>
    </div>
    <div class="person">
      <figure>
      <div class="circle">
        <img src="./imgs/XinJin.jpg" alt="Xin Jin">
      </div>
        <figcaption style="font-size: 8px;">Xin Jin<br>EIT, Ningbo</figcaption>
      </figure>
    </div>
    <div class="person">
        <figure>
      <div class="circle">
        <img src="./imgs/ZongweiWu.png" alt="Zongwei Wu">
      </div>
        <figcaption style="font-size: 8px;">Zongwei Wu<br>University of Wurzburg</figcaption>
      </figure>
    </div>
    <div class="person">
      <figure>
      <div class="circle">
        <img src="./imgs/BingchenLi.png" alt="BingchenLi">
      </div>
        <figcaption style="font-size: 8px;">Bingchen Li<br>USTC</figcaption>
      </figure>
    </div>
    <div class="person">
       <figure>
      <div class="circle">
        <img src="./imgs/YufeiWang.png" alt="YufeiWang">
      </div>
        <figcaption style="font-size: 8px;">Yufei Wang<br>Snap Research</figcaption>
      </figure>
    </div>
    <div class="person">
      <figure>
      <div class="circle">
        <img src="./imgs/WenhanYang.jpg" alt="WenhanYang">
      </div>
        <figcaption style="font-size: 8px;">Wenhan Yang<br>Pengcheng Laboratory</figcaption>
      </figure>
    </div>
    <div class="person">
      <figure>
      <div class="circle">
        <img src="./imgs/YuLi.jpg" alt="YuLi">
      </div>
        <figcaption style="font-size: 8px;">Yu Li<br>IDEA</figcaption>
      </figure>
    </div>
    <div class="person">
      <figure>
      <div class="circle">
        <img src="./imgs/ZhiboChen.png" alt="Zhibo Chen">
      </div>
        <figcaption style="font-size: 8px;">Zhibo Chen<br>USTC</figcaption>
      </figure>
    </div>
    <div class="person">
      <figure>
      <div class="circle">
        <img src="./imgs/BihanWen.jpg" alt="BihanWen">
      </div>
        <figcaption style="font-size: 8px;">Bihan Wen<br>NTU</figcaption>
      </figure>
    </div>
    <div class="person">
       <figure>
      <div class="circle">
        <img src="./imgs/robby.jpg" alt="robby">
      </div>
        <figcaption style="font-size: 8px;">Robby T. Tan<br>NUS</figcaption>
      </figure>
    </div>
    <div class="person">
       <figure>
      <div class="circle">
        <img src="./imgs/RaduTimofte.png" alt="RaduTimofte.png">
      </div>
        <figcaption style="font-size: 8px;">Radu Timofte<br>University of Wurzburg</figcaption>
      </figure>
    </div>
  </div>
</body>
          </p>
        </div>
      </div>
    </div>
    <!--/ Method. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Competition Background</h2>
        <div class="content has-text-justified">
          <p> Raindrops on camera lenses or windshields significantly reduce image visibility in human life, posing challenges for applications like surveillance and autonomous driving. Effective raindrop removal is crucial to ensuring reliable performance in these systems. However, most deraining datasets overlooked the complex environment in real life. In particular, there are few raindrop-focused datasets, and most existing datasets focus on capturing background scenes while the camera is focused on the background. Meanwhile, these datasets primarily target daytime scenarios, with limited attention to nighttime conditions.</p>

          <p>To promote the development of deraining, we introduce the first large-scale real-world raindrop-clarity dataset, which includes raindrop-focused images and nighttime scenes. Based on this dataset, we have the first NTIRE Challenge on Day and Night Raindrop Removal for Dual-Focused Images, jointly with the NTIRE workshop.</p>

          <p>The goal of this competition is to establish a new and applicable benchmark for the Day and Night Raindrop Removal for Dual-Focused Images. We are looking forward to the collaborative efforts of our participants, aiming to elevate the quality of training images. The final ranking will be made based on PSNR, SSIM, and LPIPS. </p>

          <p>The top-ranked participants will be awarded and invited to follow the CVPR submission guide for workshops to describe their solution and to submit to the associated NTIRE workshop at CVPR 2025.</p>

        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Important dates</h2>
        <div class="content has-text-justified">
           <ul>
        <li><strong>2025.01.28</strong> Release of train data (input and output) </li>
           <li><strong>2025.02.01</strong> Release of validation data (inputs only) </li>
           <li><strong>2025.02.01</strong> Validation server online </li>
          <li><strong>2025.03.15</strong> Final test data release (inputs only)</li>
            <li><strong>2025.03.21</strong> Test output results submission deadline</li>
          <li><strong>2025.03.22</strong> Fact sheets and code/executable submission deadline</li>
          <li><strong>2025.03.24</strong> Preliminary test results release to the participants</li>
           <li><strong>2025.03.28</strong> Paper submission deadline for entries from the challenge</li>
          <li><strong>2025.06.17</strong> NTIRE workshop and challenges, results, and award ceremony (CVPR 2025, Nashville, USA)</li>
           </ul>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>
 
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Data</h2>
        <div class="content has-text-justified">
          <p> The dataset named RainDrop Clarity is contributed by Yeying Jin et al (NUS). The dataset includes both daytime and nighttime scenes for training and testing. (i) The daytime raindrop dataset contains a total of 5,442 paired or triplet images, with 4,713 pairs used for training and the remaining 729 pairs for testing. (ii) The nighttime raindrop dataset consists of 9,744 paired or triplet images, where 8,655 pairs are allocated to the training set, and the remaining 1,089 pairs are reserved for the validation and test set.</p>
          <p> In this competition, the used dataset is composed of: 
                  <li>Train data: A total of 14,139 day and night dual-focused raindrop images with blurry backgrounds and their corresponding clear backgrounds are provided.</li>
                  <li>Validation data: A total of 240 day and night rainy images are provided.</li> 
                  <li>Test data: A total of 731 day and night rainy images are provided</li>
          </p>
        </div>
      </div>
    </div>
    <!--/ Method. -->
  </div>
</section>

	
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-centered">
      <img 
        src="./imgs/RaindropClarity.png"
        class="interpolation-image"
        alt="Interpolate start reference image."
        style="width: 50%; height: auto;" />
      <h2 class="subtitle">
        Raindrop Clarity Dataset
      </h2>
    </div>
  </div>
</section>

<!-- Paper video. -->
<div class="columns is-centered has-text-centered">
  <div class="column is-half"> <!-- 只占一半宽度 -->
    <h2 class="title is-3">Video</h2>
    <div class="publication-video" style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe 
        src="https://www.youtube.com/embed/YaPL0dI5l0U"
        frameborder="0" 
        allow="autoplay; encrypted-media" 
        allowfullscreen
        style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;">
      </iframe>
    </div>
  </div>
</div>
<!--/ Video. -->

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
@inproceedings{li2025ntire,
  title={NTIRE 2025 challenge on day and night raindrop removal for dual-focused images: Methods and results},
  author={Li, Xin and Jin, Yeying and Jin, Xin and Wu, Zongwei and Li, Bingchen and Wang, Yufei and Yang, Wenhan and Li, Yu and Chen, Zhibo and Wen, Bihan and others},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={1172--1183},
  year={2025}
}
@inproceedings{jin2024raindrop,
  title={Raindrop Clarity: A Dual-Focused Dataset for Day and Night Raindrop Removal},
  author={Jin, Yeying and Li, Xin and Wang, Jiadong and Zhang, Yan and Zhang, Malu},
  booktitle={European Conference on Computer Vision},
  pages={1--17},
  year={2024},
  organization={Springer}
}
    </code></pre>
  </div>
</section>







<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/lixinustc" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website adapted from the following <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
